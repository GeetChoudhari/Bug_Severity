{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_recall_curve, roc_curve, auc, f1_score\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification, RobertaConfig\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import AdamW, get_scheduler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import torch.multiprocessing as mp\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import label_binarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dataset_path, device):\n",
    "    dataset = pd.read_csv(dataset_path)\n",
    "    dataset = dataset.dropna()\n",
    "    dataset['Severity'] = dataset['Severity'].map({'trivial': 0, 'minor': 0, 'normal': 0, 'major': 1, 'critical': 1, 'blocker': 1})\n",
    "    dataset['Summary'] = dataset['Components'].astype(str) + ' \\n' + dataset['Summary']\n",
    "    X = dataset['Summary']\n",
    "    y = dataset['Severity']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    train_data = pd.DataFrame({'Summary': X_train, 'Severity': y_train})\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    class_weights = torch.tensor([1.0, float(len(y_train[y_train == 0])) / float(len(y_train[y_train == 1]))])\n",
    "    class_weights = class_weights.to(device)\n",
    "\n",
    "    class_counts = train_data['Severity'].value_counts()\n",
    "    target_count = class_counts.median()\n",
    "\n",
    "    model_name = \"roberta-base\"\n",
    "    tokenizer = RobertaTokenizer.from_pretrained(model_name)\n",
    "    #config = RobertaConfig.from_pretrained('roberta-base', num_labels=6)\n",
    "    model = RobertaForSequenceClassification.from_pretrained(model_name)#, config=config)\n",
    "\n",
    "    train_encodings = tokenizer(list(X_train), truncation=True, padding=True, max_length=512, return_tensors='pt', return_attention_mask=True)\n",
    "    test_encodings = tokenizer(list(X_test), truncation=True, padding=True, max_length=512, return_tensors='pt', return_attention_mask=True)\n",
    "\n",
    "    train_dataset = torch.utils.data.TensorDataset(train_encodings['input_ids'], train_encodings['attention_mask'], torch.tensor(list(y_train)))\n",
    "    test_dataset = torch.utils.data.TensorDataset(test_encodings['input_ids'], test_encodings['attention_mask'], torch.tensor(list(y_test)))\n",
    "\n",
    "    return train_dataset, test_dataset, class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_results(true_labels, predictions, training_data_save_path):\n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "    classification_rep = classification_report(true_labels, predictions, target_names=['non-severe','severe'])\n",
    "    f1 = f1_score(true_labels, predictions, average='weighted')  # Calculate F1 score\n",
    "\n",
    "    print(f\"Accuracy: {accuracy:.2f}\")\n",
    "    print(f\"F1 Score: {f1:.2f}\")\n",
    "    print(classification_rep)\n",
    "\n",
    "    # Visualizations\n",
    "    # Confusion Matrix\n",
    "    conf_matrix = confusion_matrix(true_labels, predictions)\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.show()\n",
    "\n",
    "    # Class Imbalance Visualization\n",
    "    sns.countplot(x=true_labels)\n",
    "    plt.title('Class Distribution')\n",
    "    plt.show()\n",
    "\n",
    "    # Assuming true_labels and predictions are one-hot encoded\n",
    "    #true_labels_bin = label_binarize(true_labels, classes=[0, 1, 2, 3, 4, 5])\n",
    "    #predictions_bin = label_binarize(predictions, classes=[0, 1, 2, 3, 4, 5])\n",
    "\n",
    "    # Precision-Recall Curve\n",
    "    precision, recall, _ = precision_recall_curve(true_labels, predictions)\n",
    "    plt.plot(recall, precision, marker='.')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Precision-Recall Curve')\n",
    "    plt.show()\n",
    "\n",
    "    # ROC Curve\n",
    "    fpr, tpr, _ = roc_curve(true_labels, predictions)\n",
    "    plt.plot(fpr, tpr, marker='.')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_and_plot(model, test_dataloader, device, model_save_path, training_data_save_path):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        progress_bar = tqdm(test_dataloader, desc='Evaluating', leave=False)\n",
    "        for batch in progress_bar:\n",
    "            input_ids, attention_mask, labels = batch\n",
    "            input_ids = input_ids.to(device)\n",
    "            attention_mask = attention_mask.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            predictions.extend(torch.argmax(outputs.logits, dim=1).cpu().numpy())\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Save the true labels and predictions for later analysis if needed\n",
    "    evaluation_results = {\n",
    "        'true_labels': true_labels,\n",
    "        'predictions': predictions\n",
    "    }\n",
    "\n",
    "    with open(f\"evaluation_results_{model_save_path}\", 'wb') as eval_file:\n",
    "        pickle.dump(evaluation_results, eval_file)\n",
    "\n",
    "    # Visualizations\n",
    "    visualize_results(true_labels, predictions, training_data_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_parallel(model, train_dataset, test_dataset, device, optimizer, model_save_path, training_data_save_path, class_weights, epoch):\n",
    "    model.to(device)\n",
    "    #model = torch.nn.DataParallel(model)  # Wrap the model for parallel training\n",
    "    train_batch_size = 32\n",
    "    test_batch_size = 64\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset, sampler=RandomSampler(train_dataset), batch_size=train_batch_size)\n",
    "    test_dataloader = DataLoader(test_dataset, sampler=SequentialSampler(test_dataset), batch_size=test_batch_size)\n",
    "    \n",
    "    epochs = epoch\n",
    "    total_steps = len(train_dataloader) * epochs\n",
    "    scheduler = get_scheduler(\"linear\", optimizer=optimizer, num_warmup_steps=int(0.1 * total_steps), num_training_steps=total_steps)\n",
    "    loss_fn = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    best_epoch = 0\n",
    "    no_improvement = 0\n",
    "\n",
    "\n",
    "    scheduler = get_scheduler(\n",
    "        \"linear\",\n",
    "        optimizer=optimizer,\n",
    "        num_warmup_steps=int(0.1 * total_steps),\n",
    "        num_training_steps=total_steps,\n",
    "    )\n",
    "\n",
    "    loss_fn = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    steps = []\n",
    "    losses = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "        progress_bar = tqdm(enumerate(train_dataloader), total=len(train_dataloader), desc=f'Epoch {epoch + 1}/{epochs}', leave=False)\n",
    "        for step, batch in progress_bar:\n",
    "            input_ids, attention_mask, labels = batch\n",
    "            input_ids = input_ids.to(device)\n",
    "            attention_mask = attention_mask.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            loss = loss.mean()  # Take the mean over the batch\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            steps.append(len(steps) + 1)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "    # Save the trained model state dictionary along with additional information\n",
    "    model_state = {\n",
    "        'model': model.state_dict(),  # Extract the model from DataParallel\n",
    "        'test_dataloader': test_dataloader,\n",
    "        'train_dataloader': train_dataloader,\n",
    "        'device': device,\n",
    "        'steps': steps,\n",
    "        'losses': losses,\n",
    "        'class_weights': class_weights\n",
    "    }\n",
    "\n",
    "    with open(model_save_path, 'wb') as model_file:\n",
    "        pickle.dump(model_state, model_file)\n",
    "\n",
    "    training_data = {\n",
    "        'steps': steps,\n",
    "        'losses': losses\n",
    "    }\n",
    "\n",
    "    with open(training_data_save_path, 'wb') as training_data_file:\n",
    "        pickle.dump(training_data, training_data_file)\n",
    "        \n",
    "    # Evaluation and plotting\n",
    "    evaluate_and_plot(model, test_dataloader, device, model_save_path, training_data_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_parallel(dataset_path, model_save_path, training_data_save_path, gpu_id, epoch):\n",
    "    device = torch.device(f\"cuda:{gpu_id}\" if torch.cuda.is_available() else \"cpu\")\n",
    "    train_dataset, test_dataset, class_weights = load_data(dataset_path, device)  # Load configuration for each dataset\n",
    "\n",
    "    # Create a new model instance for each GPU\n",
    "    model = RobertaForSequenceClassification.from_pretrained('roberta-base')\n",
    "\n",
    "    \n",
    "    optimizer = AdamW(model.parameters(), lr=1e-5, weight_decay=1e-3)\n",
    "    train_model_parallel(model, train_dataset, test_dataset, device, optimizer, model_save_path, training_data_save_path, class_weights, epoch)\n",
    "\n",
    "# def main_parallel(dataset_path, model_save_path, training_data_save_path, gpu_id, epoch):\n",
    "#     device = torch.device(f\"cuda:{gpu_id}\" if torch.cuda.is_available() else \"cpu\")\n",
    "#     train_dataset, test_dataset, class_weights = load_data(dataset_path, device)\n",
    "    \n",
    "#     model = RobertaForSequenceClassification.from_pretrained('roberta-base')\n",
    "#     optimizer = AdamW(model.parameters(), lr=1e-5, weight_decay=1e-3)\n",
    "    \n",
    "#     best_epoch = train_model_parallel(model, train_dataset, test_dataset, device, optimizer, model_save_path, training_data_save_path, class_weights, epoch)\n",
    "#     print(f\"Best epoch for dataset {dataset_path}: {best_epoch}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    dataset_paths = [{'path':\"E:/Project Dataset/Final_dataset/bugzilla_dataset.csv\",\n",
    "                       'epoch':15,\n",
    "                       'name':'bugzilla'},\n",
    "                       {'path':\"E:/Project Dataset/Final_dataset/Core_dataset.csv\",\n",
    "                       'epoch':8,\n",
    "                       'name':'Core'},\n",
    "                       {'path':\"E:/Project Dataset/Final_dataset/Firefox_dataset.csv\",\n",
    "                       'epoch':8,\n",
    "                       'name':'Firefox'},\n",
    "                       {'path':\"E:/Project Dataset/Final_dataset/Thunderbird_dataset.csv\",\n",
    "                       'epoch':10,\n",
    "                       'name':'Thunderbird'}]\n",
    "    gpus = [0, 1]  # Specify GPU ids\n",
    "\n",
    "    #processes = []\n",
    "\n",
    "    for i, dataset_path in enumerate(dataset_paths):\n",
    "        model_save_path = f\"roberta_bug_severity_model_{dataset_path['name']}.pkl\"\n",
    "        training_data_save_path = f\"training_data_{dataset_path['name']}.pkl\"\n",
    "        gpu_id = gpus[i % len(gpus)]\n",
    "        main_parallel(dataset_path['path'], model_save_path, training_data_save_path, gpu_id, dataset_path['epoch'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
