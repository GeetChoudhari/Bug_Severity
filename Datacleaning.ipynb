{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Here all the Null values are replaceed by unassigned\"\"\"\n",
    "\n",
    "# file_path1 = 'E:/Project Dataset/UpdatedData/mozilla/Bugzilla/Assigned.csv'\n",
    "# file_path2 = 'E:/Project Dataset/UpdatedData/mozilla/Core/Assigned.csv'\n",
    "# file_path3 = 'E:/Project Dataset/UpdatedData/mozilla/Firefox/Assigned.csv'\n",
    "# file_path4 = 'E:/Project Dataset/UpdatedData/mozilla/Thunderbird/Assigned.csv'\n",
    "# data = pd.read_csv(file_path1)\n",
    "# data1 = pd.read_csv(file_path2)\n",
    "# data2 = pd.read_csv(file_path3)\n",
    "# data3 = pd.read_csv(file_path4)\n",
    "\n",
    "\n",
    "# # Replace null values in the 'Assignee' column with 'Unassigned'\n",
    "\n",
    "# data['Assignee'] = data['Assignee'].fillna('Unassigned')\n",
    "# data1['Assignee'] = data1['Assignee'].fillna('Unassigned')\n",
    "# data2['Assignee'] = data2['Assignee'].fillna('Unassigned')\n",
    "# data3['Assignee'] = data3['Assignee'].fillna('Unassigned')\n",
    "\n",
    "# data.to_csv(file_path1,index=False)\n",
    "# data1.to_csv(file_path2,index=False)\n",
    "# data2.to_csv(file_path3,index=False)\n",
    "# data3.to_csv(file_path4,index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " only the record with the most recent Timestamp has been retained. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"E:/Project Dataset/UpdatedData/mozilla/Thunderbird/summary.csv\"\n",
    "data = pd.read_csv(filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'Timestamp' to datetime for proper sorting\n",
    "data['Timestamp'] = pd.to_datetime(data['Timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by 'Bug_id' and 'Timestamp' and drop duplicates while keeping the last occurrence\n",
    "data = data.sort_values(by=['Bug_id', 'Timestamp']).drop_duplicates('Bug_id', keep='last')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(filepath, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"E:/Project Dataset/UpdatedData/mozilla/Thunderbird/operating.csv\"\n",
    "df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to select the desired OS for each Bug_id group\n",
    "def select_os(group):\n",
    "    if 'All' in group['os'].values and len(group['os']) > 1:\n",
    "        # If 'All' is present and there are other OS options, remove 'All'\n",
    "        return group[group['os'] != 'All']\n",
    "    else:\n",
    "        # Otherwise, return the group as is\n",
    "        return group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to each group and concatenate the results\n",
    "df = df.groupby('Bug_id').apply(select_os).reset_index(drop=True)\n",
    "\n",
    "df.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining all the dataset and bringing it all together \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load datasets\n",
    "dataframes = {\n",
    "    'assigned': pd.read_csv('E:/Project Dataset/UpdatedData/mozilla/Thunderbird/Assigned.csv'),\n",
    "    'bug_status': pd.read_csv('E:/Project Dataset/UpdatedData/mozilla/Thunderbird/bug_status.csv'),\n",
    "    'components': pd.read_csv('E:/Project Dataset/UpdatedData/mozilla/Thunderbird/components.csv'),\n",
    "    'operating': pd.read_csv('E:/Project Dataset/UpdatedData/mozilla/Thunderbird/operating.csv'),\n",
    "    'product': pd.read_csv('E:/Project Dataset/UpdatedData/mozilla/Thunderbird/Product.csv'),\n",
    "    'resolution': pd.read_csv('E:/Project Dataset/UpdatedData/mozilla/Thunderbird/Resolution.csv'),\n",
    "    'severity': pd.read_csv('E:/Project Dataset/UpdatedData/mozilla/Thunderbird/Severity.csv'),\n",
    "    'summary': pd.read_csv('E:/Project Dataset/UpdatedData/mozilla/Thunderbird/summary.csv')\n",
    "}\n",
    "\n",
    "# Combine datasets\n",
    "base_df = dataframes['assigned'].copy()\n",
    "for name, df in dataframes.items():\n",
    "    if name != 'assigned':\n",
    "        base_df = base_df.merge(df.drop('Timestamp', axis=1), on='Bug_id', how='outer')\n",
    "\n",
    "combined_df = base_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.to_csv('combined_dataset.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath1 = \"E:/Project Dataset/UpdatedData/mozilla/Thunderbird/combined_dataset.csv\"\n",
    "data = pd.read_csv(filepath1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the Severity of dataset into Label \n",
    "\n",
    "# Mapping dictionary for severity levels\n",
    "severity_label_mapping = {\n",
    "    'blocker': 5,\n",
    "    'critical': 4,\n",
    "    'major': 3,\n",
    "    'normal': 2,\n",
    "    'minor': 1,\n",
    "    'trivial': 0\n",
    "}\n",
    "\n",
    "# Applying the mapping to create a new 'Severity_Label' column\n",
    "data['Severity_Label'] = data['Severity'].map(severity_label_mapping)\n",
    "\n",
    "data.to_csv(filepath1, index=False)\n",
    "\n",
    "# Print the first few rows to verify\n",
    "print(data[['Severity', 'Severity_Label']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'E:/Project Dataset/UpdatedData/mozilla/Thunderbird/Thunderbird_dataset.csv'  # Replace with your actual file path\n",
    "data = pd.read_csv(file_path)\n",
    "data['Severity'] = data['Severity'].map({'trivial': 0, 'minor': 0, 'normal': 0, 'major': 1, 'critical': 1, 'blocker': 1})\n",
    "data.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
